# OpenMMLab AI实战营 第一课笔记

---
![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202115351337-523975146.jpg)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230203174116047-204135633.png)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202115206188-1742424250.png)


OpenMMLab AI实战营第一节课由子豪兄讲解，课程主要内容主要围绕**计算机视觉**和**OpenMMLab开源算法体系**以及**机器学习和神经网络简介**进行展开。这里要感谢子豪兄的分享，瑞斯拜。

以下是本节课程的主要内容概要及课后补充介绍。



[TOC]



# 一、计算机视觉

## 1.1 计算机视觉是什么

​	**计算机视觉**（Computer vision）是一门研究如何使机器“看”的科学，更进一步的说，就是指用摄影机和计算机)代替人眼对目标进行识别、跟踪和测量等机器视觉，并进一步做图像处理，用计算机处理成为更适合人眼观察或传送给仪器检测的图像。

如下图的四个不同任务，即是计算机视觉领域的一系列工作。

- 图中的动物是什么？—— 图像识别
- 哪个位置有狗？——目标定位
- 狗在做什么？——动作识别
- 生成一种狗的图片？——图像生成

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202115414821-1781210671.png)

更广泛地，例如我们比较常用的微信扫一扫和人脸识别，背后的技术都用到计算机视觉技术与原理。

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202115436205-1148329273.png)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202115447055-944637412.png)

## 1.2 计算机视觉应用

- **计算机视觉主要应用领域有哪些**？

  计算机视觉是使用计算机模仿人类视觉系统的科学，让计算机拥有类似人类提取、处理、理解、分析图像以及图像序列的能力。

  大致可以分为这么几类：

  - 目标检测、图像分割、图像增强、图像生成、人脸分类识别、姿态估计、立体视觉等。

  产业链可分为**基础层**、**技术层**和**应用层**。

  - **基础层**包括硬件支持、算法支持和数据集;
  - **技术层**包括视觉技术平台、视频识别、图片识别和模式匹配;
  - **应用层**包括计算机视觉技术在智慧城市、智慧安防、智慧物流、智慧金融、手机终端和智慧商业等领域的应用。

下面是比较热门且有意思的应用：

  - 自动驾驶
  - 动漫特效
  - 航拍转地图
  - 虚拟主播
  - 视频理解与自动剪辑

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202115514762-1717569308.png)

> 自动驾驶的计算机视觉应用，主要是感知层面，视觉感知与激光雷达感知构成并辅助了车体对环境的感知，结合车辆自身状态，从而可以进行相应的决策、规划与控制。

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202115524213-969877409.png)

> 一些比较有意思的动漫特效，主要应用的关键技术有图像生成、风格迁移和人脸关键点检测。

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202115535263-2136334243.png)

> 能够根据无人机航拍图像的 GPS 信息和图像重叠度实现快速建模以及地图构建。

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202115557751-1987682682.png)

> 虚拟主播Virtual Youtuber，简称Vtuber，是近几年来兴起的网络直播形式。在这种直播当中，主播选择以一种，往往是动漫的形式的模型扮演，并以此与观众互动。我们称这些扮演者为“中之人”，同时，虚拟主播现象是中之人和模型的统一，而有时候我们往往管单纯的模型叫作虚拟主播

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202115613074-641740604.png)

> 视频内容理解的主要目标是，概括视频中出现的重要概念，打开视频内容的“黑盒”，让机器知道盒子里有什么，为下游应用提供语义信息，以便更好地对视频做管理和分发。根据结果的形式，内容理解可以分为显式和隐式两种。其中，显式是指通过视频分类相关技术，给视频打上人可以理解的文本标签。隐式主要指以向量形式表示的嵌入特征，在推荐、搜索等场景下与模型结合直接面向最终任务建模。可以粗略地理解为，前者主要面向人，后者主要面向机器学习算法。


## 1.3 计算机视觉的发展

### 1.3.1 计算机视觉的早期萌芽(1960~1980)
![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202115628167-938181309.png)

> - 1957年春天，美国国家标准局的科学家拉塞尔·基尔希为他的儿子瓦尔登拍了一张照，并将其扫描到了东部标准自动计算机（SEAC）中。为了使图片可以放进SEAC有限的存储空间中，他将图片分割成176176的网格——共30976位二进制，并进行了多次扫描。这张边长5厘米的正方形图片就是历史上第一张数字图像，从某种意义上来讲它甚至是CT扫描、卫星图像和数码摄影的鼻祖。
> - 1959年，神经生理学家大卫·休伯尔和托斯坦·维厄瑟尔通过猫的视觉实验，首次发现了视觉初级皮层神经元对于移动边缘刺激敏感，发现了视功能柱结构，**为视觉神经研究奠定了基础——促成了计算机视觉技术40年后的突破性发展，奠定了深度学习的核心准则。**
> - 到了60年代，劳伦斯罗伯茨在《三维固体的机器感知》描述了从二维图片中推导三维信息的过程，成为计算机视觉的前导之一，开创了理解三维场景为目的的计算机视觉研究。这个研究给世界带来了很大启发，并且对边缘、线条、明暗等各种特征建立了各种数据结构和推理规则。
> - 1969年秋天，贝尔实验室的两位科学家韦拉德博伊尔和乔治史密斯正忙于电荷耦合器件（CCD）的研发。它是一种将光子转化为电脉冲的器件，很快成为了高质量数字图像采集任务的新宠，逐渐应用于工业相机传感器，标志着计算机视觉走上应用舞台，投入到工业机器视觉中。

### 1.3.2 统计机器学习与模式识别(1990～2000)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202115659099-1583047722.png)

> - **1990年代**，机器学习进入了一个新阶段，研究人员开发出了更复杂的算法，比如支持向量机、集成学习、遗传算法等，这些算法可以应用于不同的领域，比如计算机视觉、自然语言处理等。
>
> - **2000年以后**，机器学习进入了一个新的发展阶段，研究人员开发出了更复杂的算法，比如深度学习、强化学习等，这些算法可以应用于更多的领域，比如自动驾驶、自然语言理解等。
>
> - 模式识别：所谓模式识别的问题就是用计算的方法根据**样本**的特征将样本划分到一定的类别中去。模式识别就是通过计算机用数学技术方法来研究模式的自动处理和判读，把环境与客体统称为“**模式**”。随着计算机技术的发展，人类有可能研究复杂的信息处理过程，其过程的一个重要形式是生命体对环境及客体的识别。模式识别以图像处理与计算机视觉、语音语言信息处理、脑网络组、类脑智能等为主要研究方向，研究人类模式识别的机理以及有效的计算方法。

#### 1.3.2.1 视觉特征

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202115717696-114235410.png)

> - **颜色特征**
>
>   描述方法：
>
>   - 颜色直方图
>   - 颜色集
>   - 颜色矩
>   - 颜色聚合向量
>   - 颜色相关图
>
> - **纹理特征**
>
>    - 统计方法（共生矩阵）
>      ![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202164218834-891265976.png)
>      GLCM（2，1)值为3说明有3对灰度为2和1的像素对角相邻。在共生矩阵基础上，又可以定义多种纹理特征：熵、能量、对比度、均匀度、相关性。
>    - 结构法
>    - 模型法
>    - 频谱法
>
> - **形状特征**
>
>    - 轮廓特征：针对物体的外边界，常使用游程长度编码方法
>    - 区域特征：统计整个区域形状，使用区域密度、区域体态比度量
>    - 局部点特征
>
> - **角点特征点**
>
>    - Harris角点
>    - SIFT
>
> - **边缘特征**
>
>    - 灭点、灭线
>    - 梯度边缘检测
>    - 非最大抑制边缘检测
>    - Canny边缘检测
>    - Robert算子、Prewitt算子、Sobel算子、Laplace 算子、LOG算子边缘检测
>

#### 1.3.2.2 ImageNet大型数据库

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202115736370-784243752.png)

> 

### 1.3.3 初有成效的视觉系统(~2010)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202115808014-1427383210.png)

> - ImageNet项目是一个用于视觉对象识别软件研究的大型可视化数据库。超过1400万的图像URL被ImageNet手动注释，以指示图片中的对象;在至少一百万个图像中，还提供了边界框。ImageNet包含2万多个类别; [2]一个典型的类别，如“气球”或“草莓”，包含数百个图像。第三方图像URL的注释数据库可以直接从ImageNet免费获得;但是，实际的图像不属于ImageNet。
>
> - 自2010年以来，ImageNet项目每年举办一次软件比赛，即ImageNet大规模视觉识别挑战赛（ILSVRC），软件程序竞相正确分类检测物体和场景。 ImageNet挑战使用了一个“修剪”的1000个非重叠类的列表。2012年在解决ImageNet挑战方面取得了巨大的突破，被广泛认为是2010年的深度学习革命的开始。

### 1.3.4 深度学习的时代

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202115829937-998613738.png)

> - 2012年，Hinton课题组为了证明深度学习的潜力，首次参加ImageNet图像识别比赛，其通过构建的CNN网络AlexNet一举夺得冠军，且碾压第二名（SVM方法）的分类性能。也正是由于该比赛，CNN吸引到了众多研究者的注意。
>
> - **AlexNet**的创新点在于:
>
> > (1)首次采用ReLU激活函数，极大增大收敛速度且从根本上解决了梯度消失问题。
> >
> > (2)由于ReLU方法可以很好抑制梯度消失问题，AlexNet抛弃了“预训练+微调”的方法，完全采用有监督训练。也正因为如此，DL的主流学习方法也因此变为了纯粹的有监督学习。
> >
> > (3)扩展了LeNet5结构，添加Dropout层减小过拟合，LRN层增强泛化能力/减小过拟合。
> >
> > (4)第一次使用GPU加速模型计算。
>
> - 2013、2014、2015、2016年，通过ImageNet图像识别比赛，DL的网络结构，训练方法，GPU硬件的不断进步，促使其在其他领域也在不断的征服战场。
>
> - 2016年3月，由谷歌（Google）旗下DeepMind公司开发的AlphaGo(基于深度学习)与围棋世界冠军、职业九段棋手李世石进行围棋人机大战，以4比1的总比分获胜；
>
> - 2016年末2017年初，该程序在中国棋类网站上以“大师”（Master）为注册帐号与中日韩数十位围棋高手进行快棋对决，连续60局无一败绩；2017年5月，在中国乌镇围棋峰会上，它与排名世界第一的世界围棋冠军柯洁对战，以3比0的总比分获胜。围棋界公认阿尔法围棋的棋力已经超过人类职业围棋顶尖水平。


### 1.3.5 时至今日

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202115850780-1591254797.png)

> 时至今日，人工智能的发展可以处理更多更有意思的事情。例如：
>
> - 文字描述生成图片
> - 视觉大模型
> - 神经渲染场
> - …

### 1.3.6 开源成为人工智能领域发展引擎

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202115905942-81769276.png)

> 近年来，人工智能领域越来越多的开源、开放，包括人工智能算法和基础平台等，促进了人工智能的高速发展。开源开放、技术创新和产业发展密切相关、互相促进。在三者的共同作用下，可以凝聚全球创新要素，加速技术创新，同时也打造技术生态，赋能产业发展。另一方面，很多标准在开源社区会先形成事实的标准，进而推动技术和产业的协同发展。

# 二、OpenMMLab开源算法体系

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202115925897-1833246963.png)

## 2.1 OpenMMLab总体介绍

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202120023856-1881011693.png)

> OpenMMLab目前基于统一的架构，根据20+的研发方向，开发了将近300+的算法和2000+的预训练模型。
>
> - 提供了统一先进的底层架构
> - 覆盖计算机视觉众多方向
> - 提供最经典、最前沿的算法支持
> - 提供统一的基准和开箱即用的工作

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202133556815-1727261198.png)

> 上图可以看到OpenMMLab开源算法体系中的开源历程，可以根据时间线来学习和了解相关的算法库。


## 2.2 OpenMMLab总体架构概览

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202133627134-531296048.png)

> OpenMMLab总体架构，主要以Pytorch为训练框架，基于计算基础库MMCV的公用底层模块与抽象训练接口，向上开发了相应的算法框架以及部署框架。

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202133746666-718955349.png)

> 在训练与部署方面，从OpenMMLab算法库到MMDeploy，结合众多硬件厂家，完成了训练-部署的一体化。

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202134052121-1106144934.png)

> 随着OpenMMLab的生态开放发展以及产学研一体化，OpenMMLab在全球范围内的影响力也越来越大。


## 2.3 算法框架介绍

### 2.3.1 MMDetection

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202175057885-975595959.png)

> MMDetection 是一个基于 PyTorch 的开源对象检测工具箱。它是[OpenMMLab](https://openmmlab.com/)项目的一部分。

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202133808225-814611503.png)

> 简单来说目标检测算法可以按照 3 个维度划分：
>
> - **按照 stage 个数划分**，常规是 one-stage 和 two-stage，但是实际上界限不是特别清晰，例如带 refine 阶段的算法 RepPoints，实际上可以认为是1.5 stage 算法，而 Cascade R-CNN 可以认为是多阶段算法，为了简单，上面图示没有划分如此细致
> - **按照是否需要预定义 anchor 划分**，常规是 anchor-based 和 anchor-free，当然也有些算法是两者混合的
> - **按照是否采用了 transformer 结构划分**，目前基于 transformer 结构的目标检测算法发展迅速，也引起了极大的关注，所以这里特意增加了这个类别的划分
>
> 不管哪种划分方式，其实都可以分成若干固定模块，然后通过模块堆叠来构建整个检测算法体系。

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202175120307-1598707403.png)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202175130198-1329888644.png)



### 2.3.2 MMDetection3D

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202133857304-1064978696.png)

> - https://github.com/open-mmlab/mmdetection3d
>
> MMDetection3D 是一个基于 PyTorch 的开源对象检测工具箱，面向下一代通用 3D 检测平台。它是 MMLab 开发的 OpenMMLab 项目的[一部分](http://mmlab.ie.cuhk.edu.hk/)。

### 2.3.3 MMClassification

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230203104412593-889743154.png)

> - https://github.com/open-mmlab/mmclassification
>
> MMClassification 是一个基于 PyTorch 的开源图像分类工具箱。它是[OpenMMLab](https://openmmlab.com/)项目的一部分。

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202133910208-2105967992.png)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230203104452006-810181367.png)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230203104503959-829456259.png)

### 2.3.4 MMSegmentation

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202175159960-1874863623.png)

> - https://github.com/open-mmlab/mmsegmentation
>
> MMSegmentation 是一个基于 PyTorch 的开源语义分割工具箱。它是[OpenMMLab](https://openmmlab.com/)项目的一部分。
>
> master 分支适用于**PyTorch 1.5+**。

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202133923238-1679513499.png)



![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202175212871-2073708037.png)

### 2.3.5 MMPose & MMHuman3D

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230203111558845-677633556.png)

> - https://github.com/open-mmlab/mmpose-
>
> MMPose 是一个基于 PyTorch 的姿态估计开源工具箱。它是[OpenMMLab 项目](https://github.com/open-mmlab)的一部分。
>
> master 分支适用于**PyTorch 1.5+**。


![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202133935932-711562383.png)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230203111622386-578275308.png)

> - https://github.com/open-mmlab/mmhuman3d
>
> MMHuman3D 是一个基于 PyTorch 的开源代码库，用于在计算机视觉和计算机图形学中使用 3D 人体参数模型。它是[OpenMMLab](https://openmmlab.com/)项目的一部分。
>
> 主要分支适用于**PyTorch 1.7+**。

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230203111632942-1945069133.png)


### 2.3.6 MMTracking

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230203112046493-1937518133.png)

> https://github.com/open-mmlab/mmtracking
>
> - MMTracking 是 PyTorch 开源的视频感知工具箱。它是[OpenMMLab](https://openmmlab.com/)项目的一部分。
>
>   master 分支适用于**PyTorch1.5+**。

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202133949646-555579161.png)

### 2.3.7 MMAction2

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230203111645000-1177500763.png)

> - https://github.com/open-mmlab/mmaction2
>
> MMAction2 是一个基于 PyTorch 的视频理解开源工具箱。它是[OpenMMLab](https://openmmlab.com/)项目的一部分。
>
> master 分支适用于**PyTorch 1.5+**。

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202134004302-2011880386.png)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202175300495-717511433.png)


### 2.3.8 MMOCR

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230203111828076-669369482.png)

> - https://github.com/open-mmlab/mmocr
> 
>MMOCR 是一个基于 PyTorch 和 mmdetection 的开源工具箱，用于文本检测、文本识别以及相应的下游任务，包括关键信息提取。它是[OpenMMLab](https://openmmlab.com/)项目的一部分。
> 
>主要分支适用于**PyTorch 1.6+**


![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202134021247-267170742.png)

### 2.3.9 MMEditing

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202134034658-2116460718.png)

  > - https://github.com/open-mmlab/mmediting
  >
  > MMEditing 是一个基于 PyTorch 的开源图像和视频编辑工具箱。它是[OpenMMLab](https://openmmlab.com/)项目的一部分。目前MMEditing支持：
  >
  > master 分支适用于**PyTorch 1.5+**。

## 2.4 行业应用案例

OpenMMLab作为算法生态的关键一环，在行业应用案例中与上下游结合，其中对于上游芯片适配了支持，通过算法生态带动国产化软硬件生态链发展。
同时，也不断服务于下游的头部企业用户，加速计算机视觉技术落地，提高行业研发效率，服务国计民生。

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202134201029-2101801520.png)

> 上游芯片厂商主要包括：摩尔线程、NVIDIA、Intel、壁仞科技、沐璐集成电路、、燧原科技、GRAPHCORE、寒武纪、华为、中科曙光。

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202134215753-542604602.png)

## 2.5 OpenMMLab2.0整体介绍

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202134756262-184914180.png)

下面从以下几个方面来进行介绍：

> - 通用：强大的训练器案例、70行训练TIMM模型
> - 灵活：可插拔模块、训练流程控制、日志与可视化
> - 开放统一：模块抽象、执行入口、训练流程、数据接口
> - 迭代计划

### 2.5.1 整体架构

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202134818457-1168762969.png)

> - **新架构**
>   基于 MMEngine，OpenMMLab 2.0 的核心架构焕然一新，具有通用、统一、灵活三大特点。
>- 新的架构除了**通用**、**统一**、**灵活**等三大亮点，还针对各个模块进行了精心设计和优化（设计的时间和开发时间五五开），平衡兼顾了简单性、扩展性和效率。在代码可读性和文档方面，我们对 MMEngine 的要求也比以往的各个算法库都要严格，希望大家在阅读 MMEngine 的源码时还能有所收获，也欢迎大家试用 MMEngine。
> 

### 2.5.2 通用：强大的训练器

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202134836125-177353029.png)

> **通用**
> OpenMMLab 2.0 中的 20 多个算法任务都基于一个强大且通用的训练器。和 OpenMMLab 1.0 中的训练器相比，新的训练器以统一的方式实现了数据、模型、评测等组件的构造流程供各算法库调用，以更加可拓展的方式支持了不同芯片环境（CPU，GPU，Apple M1，MLU等）下的分布式和非分布式训练，并支持了一些最新的大模型训练技术如 FullyShardedDataParallel。下游的各种算法库都可以直接使用这个训练器，在简化代码的同时，通过依赖最新的 MMEngine 享受最新的训练技术和芯片支持。
> 同时，这个通用的训练器还支持被 OpenMMLab 体系外的算法库单独使用，它可以做到以少量代码训练不同任务：例如仅使用 80 行代码训练 imagenet（而 pytorch example 需要 400行），100 行代码训练 CLIP（OpenCLIP 中有上千行训练代码） ，还能轻松兼容当前流行的算法库中的模型，例如 TIMM，TorchVision 和 Detectron2。

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202134858471-1502283608.png)

### 2.5.3 统一：模块抽象

> **统一**
> OpenMMLab 1.0 中的各算法库分别支持了**感知**、**生成**、预训练等 30 多个算法方向，每个算法方向中还有各种不同的算法和训练范式，各算法库也因此在接口上存在细微差别，难以兼容，使得支持新芯片和训练技术的开发成本和算法库数量成正比。

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202134912383-1288609437.png)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202134923166-1395568784.png)

> 统一后的模块抽象：
>
> - 抽象模块数据丰富
> - 清理了函数式定义，增加模块或者模块方法


### 2.5.4 统一：训练流程

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202135105283-1092727140.png)

> 统一后的训练流程：
>
> - 统一了20多个算法任务的训练流程
> - 支持自监督、半监督、少样本学习

### 2.5.5 统一：数据接口

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202134953579-1086616710.png)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202135150152-1908314965.png)


### 2.5.6 灵活：日志与可视化

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202135239461-1962579534.png)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202135251243-1174060301.png)

> **灵活**
> 在 OpenMMLab 2.0 中，我们对算法训练流程进行了更细粒度的模块化设计，使得整个训练流程中有了更多可定制化的空间，包括在训练器中增加更多抽象模块、更多可自定义的插入点，和组件之间的信息交流渠道 MessageHub 等。上述贴心的设计提供了一个“乐高”式的训练流程 ，用户可以像拼乐高一样，随心所欲地“插拔”各种模块，实现训练流程的定制化，
>
> 例如：根据迭代数、 loss 和评测结果等动态调整的训练流程、优化策略和数据增强策略，实现 early stopping，ReduceLROnPlateau 等
> 任意形式的模型权重平均，如 Exponential Momentum Average (EMA) 和 Stochastic Weight Averaging (SWA)
> 训练过程中针对任意数据和任意节点的灵活可视化和日志控制、逐参数的优化配置、混合精度训练的灵活控制。


### 2.5.7 迭代计划

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202135305205-683481323.png)


# 三、机器学习和神经网络简介

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202135320568-944170330.png)


## 3.1 机器学习基础

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202135528640-2081618355.png)



### 3.1.1 机器学习是什么

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202135643406-993044875.png)

### 3.1.2 为什么要让“机器”去“学习”

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202135746443-672906296.png)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202135807560-289051397.png)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202135817457-922714897.png)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202135829931-440744023.png)


### 3.1.3 机器学习是什么

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202135948072-508674355.png)


### 3.1.4 机器学习的典型范式

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202140004065-859401810.png)


## 3.2 机器学习中的分类问题

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202140030011-24014692.png)


### 3.2.1 特征与分类

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202140043138-2124377761.png)


### 3.2.2 线性分类器

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202140059484-1399115177.png)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202140120630-347636206.png)


### 3.2.3 如何求解分界面

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202140144264-1202474430.png)

### 3.2.4 感知机Perceptron：从数据中学习

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202140159601-806267850.png)


### 3.2.5 机器学习的基本流程

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202140210255-1531160846.png)


## 3.3 神经网络的结构


### 3.3.1 线性分类器与非线性分类器

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202140230690-2083654279.png)

#### 3.3.1.1 异或问题

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202140255235-1055716195.png)


#### 3.3.1.2 非线性分类器

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202140307979-1803595897.png)


### 3.3.2 神经元

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202140324819-1264177754.png)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202140341062-223320342.png)

### 3.3.3 多层感知器

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202140350249-1942757603.png)

### 3.3.4 多分类任务

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202140428444-923908741.png)


## 3.4 神经网络的训练


### 3.4.1 神经网络训练介绍

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202140448061-711428124.png)


### 3.4.2 损失函数

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202140511185-810063825.png)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202140535689-190040538.png)

### 3.4.3 梯度下降算法

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202140613410-944718804.png)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202140841452-318190492.png)


#### 3.4.3.1 梯度计算

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202140900442-796999883.png)



#### 3.4.3.2 反向传播算法

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202140915360-1431542179.png)


#### 3.4.3.3 梯度下降算法的具体实现

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202140934895-120593783.png)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202140958884-457590043.png)


#### 3.4.3.4 优化器

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202141017863-1292965815.png)


#### 3.4.3.5 自适应梯度算法

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202141038263-1359630967.png)

#### 3.4.3.6 基于梯度下降训练神经网络的整体流程

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202141058668-658285745.png)


### 3.4.4 欠拟合、拟合与过拟合

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202141118649-1424757795.png)


### 3.4.5 早停Early Stopping

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202141136146-1104881909.png)


## 3.5 卷积神经网络

### 3.5.1 Why CNN？

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202141228346-13116335.png)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202141244848-881735834.png)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202141319582-1932144718.png)

### 3.5.2 卷积层Convolutional Layer

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202141404802-2056048344.png)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202141422312-2017447777.png)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202141436777-2096752341.png)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202141457277-713127063.png)

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202141521762-342588454.png)


#### 3.5.2.1卷积的变形

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202141630637-474057207.png)


#### 3.5.4.2 卷积的边缘填充

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202141716915-735748258.png)



#### 3.5.2.3 卷积的步长

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202141731315-431372074.png)


### 3.5.3 激活层Activation Layer

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202141745815-284237846.png)


#### 3.5.3.1 常用激活函数

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202141806510-1036565659.png)


#### 3.5.3.2 Sigmoid


#### 3.5.3.3 tanh


#### 3.5.3.4 ReLU


#### 3.5.3.5 Leaky ReLU


#### 3.5.3.6 PReLU


#### 3.5.3.7 ELU


### 3.5.4 池化层

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202141846356-996515591.png)

### 3.5.5 全连接层

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202141901666-316965842.png)


### 3.5.6 概览输出层

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202141929804-1856855059.png)


### 3.5.4 用特征与分类的角度理解CNN

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202141954974-2028860511.png)


## 3.6 Pytorch环境配置与基础使用

### 3.6.1 Pytorch介绍

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202142035864-1143812956.png)

### 3.6.2 Pytorch环境配置

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202142047549-185763805.png)

### 3.6.3 Pytorch的基本模块

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202142105869-1719783889.png)

#### 3.6.3.1 数值计算库torch

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202142123898-665529118.png)


#### 3.6.3.2 自动求导torch.autograd

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202142140939-1097296121.png)


#### 3.6.3.3 函数库torch.nn.funcitonal

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202142154963-835258943.png)


#### 3.6.3.4 通用模型封装torch.nn.Module

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202142211668-593138284.png)


#### 3.6.3.5 优化器torch.optim

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202142240969-2071221166.png)


#### 3.6.3.6 数据工具torch.utils.data

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202142252353-1717650373.png)


### 3.6.4 Pytorch神经网络demo演示及讲解

![](https://img2023.cnblogs.com/blog/1571518/202302/1571518-20230202142302450-2026664951.png)
